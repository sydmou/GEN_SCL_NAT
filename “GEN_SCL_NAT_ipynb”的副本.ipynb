{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sydmou/GEN_SCL_NAT/blob/Inference/%E2%80%9CGEN_SCL_NAT_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yghILndFvE7d",
        "outputId": "d6309dfd-2c7a-417f-8823-94e15ab0d0b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ihs2CdEAvLL3",
        "outputId": "e45f5d0f-284a-46a7-e7d7-3a8c526f682b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 24 03:16:26 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3HwFe8wvRd6",
        "outputId": "7d7777f2-812d-466c-bcf7-3535c4f53255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.19.0\n",
            "  Downloading transformers-4.19.0-py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.19.0)\n",
            "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (2023.7.22)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed tokenizers-0.12.1 transformers-4.19.0\n"
          ]
        }
      ],
      "source": [
        "pip install transformers==4.19.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GNj6DVTTvXhz"
      },
      "outputs": [],
      "source": [
        "!pip install torch>=1.10.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YPvtZOKvus2",
        "outputId": "9ac491c4-a9fc-48cd-a4d4-575eceab96a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning==1.8.6\n",
            "  Downloading pytorch_lightning-1.8.6-py3-none-any.whl (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.3/800.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.8.6) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.8.6) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.8.6) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.8.6) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.8.6) (2023.6.0)\n",
            "Collecting tensorboardX>=2.2 (from pytorch_lightning==1.8.6)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics>=0.7.0 (from pytorch_lightning==1.8.6)\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.8.6) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.8.6) (4.5.0)\n",
            "Collecting lightning-utilities!=0.4.0,>=0.3.0 (from pytorch_lightning==1.8.6)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning==1.8.6) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning==1.8.6) (3.8.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities!=0.4.0,>=0.3.0->pytorch_lightning==1.8.6) (67.7.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.2->pytorch_lightning==1.8.6) (3.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->pytorch_lightning==1.8.6) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->pytorch_lightning==1.8.6) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->pytorch_lightning==1.8.6) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->pytorch_lightning==1.8.6) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->pytorch_lightning==1.8.6) (2.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->pytorch_lightning==1.8.6) (2.1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning==1.8.6) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->pytorch_lightning==1.8.6) (1.3.0)\n",
            "Installing collected packages: tensorboardX, lightning-utilities, torchmetrics, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.10.0 pytorch_lightning-1.8.6 tensorboardX-2.6.2.2 torchmetrics-1.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install pytorch_lightning==1.8.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzu7OXc2v1JN",
        "outputId": "b4212d10-522d-4521-9ea4-d19f8cd1321b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece==0.1.97\n",
            "  Downloading sentencepiece-0.1.97-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ],
      "source": [
        "pip install sentencepiece==0.1.97"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ft9IGfa4v9-E"
      },
      "outputs": [],
      "source": [
        "import numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amiEPxLlwLIT",
        "outputId": "dfb650f7-71ec-478f-ff19-3cbc2bfcd084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEBYPHXzwPKA",
        "outputId": "0989d25d-46f2-489d-b968-544290efd59e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/ColabNotebooks/ABSA-QUAD-master'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/ColabNotebooks/ABSA-QUAD-master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-b4q6hDwWYh"
      },
      "outputs": [],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f1iJ3VO4N7y",
        "outputId": "d8d8c917-2875-4f73-e0ae-f33e800afe41"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mK_FgmAwYyw",
        "outputId": "b0331195-465e-411b-d06e-8f2264ce2a81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-15 10:03:25.031202: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-15 10:03:25.939768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            " ============================== NEW EXP: ASQP on rest16 ============================== \n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n",
            "Here is an example (from the dev set):\n",
            "Input words: The pizza was pretty good and huge .\n",
            "Input tuples: [['pizza', 'food quality', 'positive', 'good'], ['pizza', 'food style_options', 'positive', 'huge']]\n",
            "Total examples = 316\n",
            "Input : Great friendly service, Fast seating, Fast Delivery, Excellent sushi.\n",
            "Output: service general is great because service is Great friendly [SSEP] service general is great because seating is Fast [SSEP] service general is great because Delivery is Fast [SSEP] food quality is great because sushi is Excellent\n",
            "\n",
            "****** Conduct Training ******\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus='1')` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices='1')` instead.\n",
            "  rank_zero_deprecation(\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "\n",
            "  | Name  | Type                       | Params\n",
            "-----------------------------------------------------\n",
            "0 | model | T5ForConditionalGeneration | 222 M \n",
            "-----------------------------------------------------\n",
            "222 M     Trainable params\n",
            "0         Non-trainable params\n",
            "222 M     Total params\n",
            "891.614   Total estimated model params size (MB)\n",
            "Sanity Checking: 0it [00:00, ?it/s]Input words: The pizza was pretty good and huge .\n",
            "Input tuples: [['pizza', 'food quality', 'positive', 'good'], ['pizza', 'food style_options', 'positive', 'huge']]\n",
            "Total examples = 316\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Input words: I had the duck breast special on my last visit and it was incredible .\n",
            "Input tuples: [['duck breast special', 'food quality', 'positive', 'incredible']]\n",
            "Total examples = 1264\n",
            "Epoch 0:  61% 60/99 [00:48<00:31,  1.24it/s, loss=0.506, v_num=21]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  81% 80/99 [01:04<00:15,  1.24it/s, loss=0.506, v_num=21]\n",
            "Epoch 0: 100% 99/99 [01:09<00:00,  1.42it/s, loss=0.436, v_num=21]\n",
            "Epoch 1:  61% 60/99 [00:52<00:34,  1.14it/s, loss=0.26, v_num=21] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  81% 80/99 [01:09<00:16,  1.15it/s, loss=0.26, v_num=21]\n",
            "Epoch 1: 100% 99/99 [01:15<00:00,  1.32it/s, loss=0.286, v_num=21]\n",
            "Epoch 2:  61% 60/99 [00:52<00:34,  1.14it/s, loss=0.197, v_num=21]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  81% 80/99 [01:09<00:16,  1.15it/s, loss=0.197, v_num=21]\n",
            "Epoch 2: 100% 99/99 [01:15<00:00,  1.31it/s, loss=0.2, v_num=21]  \n",
            "Epoch 3:  61% 60/99 [00:52<00:34,  1.14it/s, loss=0.116, v_num=21]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  81% 80/99 [01:09<00:16,  1.15it/s, loss=0.116, v_num=21]\n",
            "Epoch 3: 100% 99/99 [01:15<00:00,  1.31it/s, loss=0.132, v_num=21]\n",
            "Epoch 4:  61% 60/99 [00:53<00:34,  1.13it/s, loss=0.117, v_num=21] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  81% 80/99 [01:10<00:16,  1.14it/s, loss=0.117, v_num=21]\n",
            "Epoch 4: 100% 99/99 [01:15<00:00,  1.31it/s, loss=0.109, v_num=21]\n",
            "Epoch 5:  61% 60/99 [00:53<00:34,  1.13it/s, loss=0.0742, v_num=21]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:  81% 80/99 [01:10<00:16,  1.14it/s, loss=0.0742, v_num=21]\n",
            "Epoch 5: 100% 99/99 [01:15<00:00,  1.31it/s, loss=0.0831, v_num=21]\n",
            "Epoch 6:  61% 60/99 [00:53<00:34,  1.12it/s, loss=0.0535, v_num=21]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6:  81% 80/99 [01:11<00:16,  1.12it/s, loss=0.0535, v_num=21]\n",
            "Epoch 6: 100% 99/99 [01:16<00:00,  1.29it/s, loss=0.0658, v_num=21]\n",
            "Epoch 7:  61% 60/99 [00:53<00:34,  1.12it/s, loss=0.057, v_num=21] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7:  81% 80/99 [01:10<00:16,  1.14it/s, loss=0.057, v_num=21]\n",
            "Epoch 7: 100% 99/99 [01:16<00:00,  1.30it/s, loss=0.0572, v_num=21]\n",
            "Epoch 8:  61% 60/99 [00:53<00:34,  1.13it/s, loss=0.0472, v_num=21]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8:  81% 80/99 [01:09<00:16,  1.14it/s, loss=0.0472, v_num=21]\n",
            "Epoch 8: 100% 99/99 [01:15<00:00,  1.31it/s, loss=0.0528, v_num=21]\n",
            "Epoch 9:  61% 60/99 [00:52<00:34,  1.13it/s, loss=0.0485, v_num=21]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  81% 80/99 [01:09<00:16,  1.14it/s, loss=0.0485, v_num=21]\n",
            "Epoch 9: 100% 99/99 [01:15<00:00,  1.31it/s, loss=0.0374, v_num=21]\n",
            "Epoch 10:  61% 60/99 [00:54<00:35,  1.10it/s, loss=0.0397, v_num=21]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 10:  81% 80/99 [01:11<00:17,  1.12it/s, loss=0.0397, v_num=21]\n",
            "Epoch 10: 100% 99/99 [01:17<00:00,  1.28it/s, loss=0.031, v_num=21] \n",
            "Epoch 11:  61% 60/99 [00:53<00:34,  1.13it/s, loss=0.0325, v_num=21]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 11:  81% 80/99 [01:09<00:16,  1.14it/s, loss=0.0325, v_num=21]\n",
            "Epoch 11: 100% 99/99 [01:15<00:00,  1.31it/s, loss=0.0396, v_num=21]\n",
            "Epoch 12:  61% 60/99 [00:54<00:35,  1.10it/s, loss=0.0368, v_num=21]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 12:  81% 80/99 [01:11<00:16,  1.12it/s, loss=0.0368, v_num=21]\n",
            "Epoch 12: 100% 99/99 [01:17<00:00,  1.28it/s, loss=0.0262, v_num=21]\n",
            "Epoch 13:  61% 60/99 [00:52<00:34,  1.13it/s, loss=0.0238, v_num=21]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 13:  81% 80/99 [01:09<00:16,  1.15it/s, loss=0.0238, v_num=21]\n",
            "Epoch 13: 100% 99/99 [01:15<00:00,  1.31it/s, loss=0.0217, v_num=21]\n",
            "Epoch 14:  61% 60/99 [01:02<00:40,  1.04s/it, loss=0.021, v_num=21] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 14:  81% 80/99 [01:19<00:18,  1.01it/s, loss=0.021, v_num=21]\n",
            "Epoch 14: 100% 99/99 [01:25<00:00,  1.16it/s, loss=0.0246, v_num=21]\n",
            "Epoch 15:  61% 60/99 [00:53<00:34,  1.12it/s, loss=0.0285, v_num=21]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 15:  81% 80/99 [01:10<00:16,  1.14it/s, loss=0.0285, v_num=21]\n",
            "Epoch 15: 100% 99/99 [01:15<00:00,  1.30it/s, loss=0.0304, v_num=21]\n",
            "Epoch 16:  61% 60/99 [00:54<00:35,  1.10it/s, loss=0.0225, v_num=21]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 16:  81% 80/99 [01:12<00:17,  1.11it/s, loss=0.0225, v_num=21]\n",
            "Epoch 16: 100% 99/99 [01:17<00:00,  1.28it/s, loss=0.0167, v_num=21]\n",
            "Epoch 17:  61% 60/99 [00:52<00:34,  1.14it/s, loss=0.0174, v_num=21]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 17:  81% 80/99 [01:09<00:16,  1.15it/s, loss=0.0174, v_num=21]\n",
            "Epoch 17: 100% 99/99 [01:15<00:00,  1.32it/s, loss=0.0197, v_num=21]\n",
            "Epoch 18:  61% 60/99 [00:52<00:34,  1.14it/s, loss=0.0221, v_num=21]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 18:  81% 80/99 [01:09<00:16,  1.15it/s, loss=0.0221, v_num=21]\n",
            "Epoch 18: 100% 99/99 [01:15<00:00,  1.31it/s, loss=0.0131, v_num=21]\n",
            "Epoch 19:  61% 60/99 [00:53<00:34,  1.13it/s, loss=0.0668, v_num=21]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 19:  81% 80/99 [01:09<00:16,  1.14it/s, loss=0.0668, v_num=21]\n",
            "Epoch 19: 100% 99/99 [01:15<00:00,  1.31it/s, loss=0.0352, v_num=21]\n",
            "Epoch 19: 100% 99/99 [01:15<00:00,  1.31it/s, loss=0.0352, v_num=21]`Trainer.fit` stopped: `max_epochs=20` reached.\n",
            "Epoch 19: 100% 99/99 [01:45<00:00,  1.07s/it, loss=0.0352, v_num=21]\n",
            "Finish training and saving the model!\n",
            "\n",
            "****** Conduct Evaluating with the last state ******\n",
            "Input words: Perfect on a cold day .\n",
            "Input tuples: [['NULL', 'food quality', 'positive', 'Perfect']]\n",
            "\n",
            "Input words: Perfect on a cold day .\n",
            "Input tuples: [['NULL', 'food quality', 'positive', 'Perfect']]\n",
            "Total examples = 544\n",
            "100% 17/17 [01:48<00:00,  6.38s/it]\n",
            "\n",
            "Results:\n",
            "number of gold spans: 799, predicted spans: 861, hit: 465\n",
            "{'precision': 0.5400696864111498, 'recall': 0.5819774718397998, 'f1': 0.5602409638554218}\n"
          ]
        }
      ],
      "source": [
        "!sh run.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xi4hEG0f6Rap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDfFqOYHxSQ5",
        "outputId": "d802586d-8d24-4274-aa85-83866781fca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting parse\n",
            "  Downloading parse-1.19.1-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: parse\n",
            "Successfully installed parse-1.19.1\n"
          ]
        }
      ],
      "source": [
        "pip install parse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-alkMJtJxDRj",
        "outputId": "3408543e-5c2f-468e-95cd-4109764b545d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1tmoh4YCT1-JFQGYMddX5uxkcxk2qkKnU/GEN_SCL_NAT-main/source\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/GEN_SCL_NAT-main/source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqrOVPXvxf8s",
        "outputId": "a8edc374-d51d-435c-b87a-43205bfad087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'=1.10.0'                 figureE35.png                    figureLaptopE30batch16EAEO.png\n",
            " category_mappings.json   figureE40.png                    figureLaptopE31batch16EAEO.png\n",
            " \u001b[0m\u001b[01;34mdata\u001b[0m/                    figureE45.png                    figureLaptopE5batch16EAEO.png\n",
            " data_utils.py            figureE5_16.png                  generate_data.py\n",
            " eval_utils.py            figureE5.png                     gen_scl_nat_main1.py\n",
            " figure1.png              figureEAE20.png                  gen_scl_nat_main.py\n",
            " figureE10.png            figureEAE30.png                  \u001b[01;34minference_outputs\u001b[0m/\n",
            " figureE15.png            figureEAE35.png                  infer_restaurant.sh\n",
            " figureE1.png             figureEAE40.png                  losses.py\n",
            " figureE20.png            figureEAE42.png                  Miniconda3-latest-Linux-x86_64.sh\n",
            " figureE25.png            figureEAE45.png                  \u001b[01;34m__pycache__\u001b[0m/\n",
            " figureE30_16.png         figureLaptopE10batch16EAEO.png   utils.py\n",
            " figureE30.png            figureLaptopE15batch16EAEO.png\n",
            " figureE35_16.png         figureLaptopE20batch16EAEO.png\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4N0RoGLxE2Q",
        "outputId": "5e006604-52e2-4f2d-e74f-4497b7a849e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-24 03:21:16.282320: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-24 03:21:16.282374: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-24 03:21:16.282409: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-24 03:21:16.290088: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-24 03:21:17.359829: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "acos_laptop_dataIgen_scl_natIt5-baseIbeamsI5IwdI0.0Imax_epochsI42IesI0IaccI1IlrI9e-05Icont_lossI0.05Icont_tempI0.25ItruncIFalseIseedI123Irestaurant_output\n",
            "Global seed set to 123\n",
            "Downloading: 100% 773k/773k [00:00<00:00, 48.8MB/s]\n",
            "Downloading: 100% 1.18k/1.18k [00:00<00:00, 5.16MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n",
            "Sentiment distribution\n",
            "Counter({2: 1584, 0: 1025, 1: 174, 3: 151})\n",
            "aspect : [1, 0, 0, 1, 2, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 2, 1, 1, 0, 2, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 1, 0, 1, 2, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 2, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 2, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 2, 0, 1, 0, 1, 2, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 2, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 2, 0, 1, 1, 1, 2, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 2, 0, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 1, 2, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 0, 0, 0, 1, 2, 1, 0, 1, 0, 1, 2, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 2, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 1, 1, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 2, 2, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 2, 1, 1, 1, 1, 0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 2, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 2, 2, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 2, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 2, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 2, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 0, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 0, 1, 2, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 1]\n",
            "aspect_opinion : [2, 3, 3, 2, 2, 0, 3, 1, 0, 2, 0, 1, 2, 2, 2, 3, 3, 0, 2, 2, 2, 2, 2, 0, 0, 1, 0, 0, 2, 2, 2, 0, 0, 3, 2, 2, 0, 3, 3, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 2, 1, 3, 0, 0, 1, 2, 2, 0, 2, 3, 0, 1, 3, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 3, 2, 1, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 3, 1, 1, 0, 1, 3, 0, 0, 0, 2, 2, 0, 2, 0, 0, 3, 3, 3, 3, 0, 3, 0, 0, 0, 3, 0, 3, 3, 0, 2, 2, 1, 0, 0, 2, 0, 1, 1, 0, 0, 2, 2, 2, 2, 2, 2, 1, 0, 2, 0, 2, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 2, 0, 1, 0, 2, 3, 2, 2, 0, 2, 2, 2, 3, 0, 1, 1, 2, 0, 2, 2, 2, 0, 1, 3, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 3, 3, 2, 2, 2, 2, 1, 0, 0, 2, 0, 0, 0, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 3, 1, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 1, 0, 0, 2, 0, 2, 3, 0, 0, 0, 2, 0, 0, 0, 2, 0, 1, 1, 0, 3, 0, 1, 0, 2, 2, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 3, 0, 0, 3, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 3, 2, 0, 2, 2, 2, 0, 0, 0, 1, 0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 1, 2, 3, 1, 1, 2, 1, 2, 1, 2, 2, 0, 0, 1, 3, 0, 1, 3, 3, 2, 1, 3, 3, 2, 1, 0, 0, 0, 0, 0, 0, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 3, 0, 3, 1, 0, 1, 1, 1, 0, 0, 0, 0, 2, 1, 3, 1, 1, 0, 0, 0, 2, 1, 2, 1, 1, 1, 1, 1, 2, 0, 3, 1, 0, 2, 1, 3, 0, 0, 3, 0, 0, 3, 3, 0, 1, 0, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 1, 2, 2, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 2, 0, 1, 1, 3, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 1, 3, 2, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 3, 3, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 3, 1, 2, 2, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 3, 1, 1, 0, 2, 1, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 3, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 3, 2, 0, 0, 2, 0, 1, 1, 1, 2, 2, 2, 1, 1, 0, 3, 1, 0, 0, 2, 0, 0, 2, 1, 0, 0, 0, 3, 2, 1, 0, 0, 1, 1, 1, 3, 0, 0, 0, 0, 0, 2, 2, 0, 1, 1, 1, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 1, 1, 2, 0, 0, 1, 0, 3, 3, 0, 0, 1, 2, 0, 1, 0, 2, 0, 2, 2, 1, 0, 0, 0, 0, 0, 1, 3, 3, 3, 1, 3, 3, 1, 0, 0, 1, 2, 2, 2, 2, 0, 1, 1, 1, 0, 0, 2, 2, 0, 0, 0, 2, 2, 1, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 1, 1, 1, 0, 0, 0, 3, 0, 1, 0, 0, 1, 2, 2, 2, 3, 3, 3, 3, 2, 0, 0, 1, 1, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 1, 3, 0, 3, 1, 0, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 2, 0, 1, 2, 1, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 3, 2, 0, 3, 0, 3, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 3, 3, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 3, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 3, 1, 1, 1, 1, 1, 2, 0, 0, 3, 0, 3, 1, 1, 1, 0, 1, 0, 0, 3, 3, 2, 2, 0, 0, 2, 2, 3, 1, 0, 2, 3, 0, 1, 1, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 3, 3, 0, 1, 1, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 3, 0, 3, 2, 1, 0, 2, 1, 0, 0, 3, 2, 1, 0, 1, 2, 0, 2, 3, 2, 2, 2, 1, 0, 2, 2, 0, 0, 1, 1, 0, 2, 0, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 1, 2, 2, 2, 0, 2, 0, 2, 1, 1, 2, 1, 0, 0, 0, 0, 2, 2, 2, 0, 2, 0, 3, 3, 2, 2, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 2, 1, 2, 0, 0, 3, 0, 1, 0, 2, 0, 1, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 3, 1, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 2, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 0, 2, 2, 2, 0, 3, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 3, 0, 0, 2, 2, 0, 1, 0, 3, 0, 0, 2, 0, 0, 0, 2, 0, 1, 1, 1, 1, 0, 1, 0, 2, 2, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 2, 0, 1, 0, 2, 3, 1, 1, 0, 2, 0, 2, 3, 0, 1, 3, 1, 1, 2, 2, 1, 3, 2, 0, 0, 2, 1, 2, 3, 2, 1, 3, 3, 2, 0, 1, 2, 2, 3, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 1, 2, 2, 3, 0, 1, 2, 2, 3, 0, 2, 3, 0, 0, 2, 2, 2, 2, 3, 0, 2, 2, 3, 2, 3, 0, 3, 3, 3, 2, 2, 0, 3, 3, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 1, 2, 1, 1, 3, 3, 2, 2, 2, 3, 3, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 2, 0, 3, 0, 1, 2, 2, 2, 2, 0, 3, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 0, 2, 0, 0, 0, 0, 1, 0, 1, 0, 2, 1, 0, 3, 2, 2, 0, 3, 2, 0, 2, 3, 3, 2, 2, 0, 3, 0, 2, 0, 2, 0, 0, 2, 3, 1, 0, 2, 2, 0, 0, 2, 3, 2, 0, 3, 0, 1, 0, 0, 0, 2, 0, 1, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 2, 2, 0, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 1, 2, 2, 3, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 3, 3, 3, 1, 0, 0, 0, 2, 2, 2, 1, 3, 3, 0, 2, 2, 1, 1, 1, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 3, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 1, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 0, 0, 2, 2, 1, 2, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 2, 3, 0, 1, 1, 0, 1, 0, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 3, 1, 1, 0, 0, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 2, 3, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 3, 0, 0, 0, 0, 0, 0, 3, 0, 2, 2, 2, 2, 3, 1, 0, 0, 2, 2, 0, 2, 2, 0, 0, 1, 0, 2, 0, 2, 2, 2, 1, 2, 2, 0, 0, 0, 2, 2, 0, 3, 3, 0, 1, 0, 0, 1, 2, 0, 0, 0, 0, 0, 3, 0, 3, 0, 1, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 2, 2, 0, 0, 0, 1, 0, 0, 3, 3, 1, 2, 0, 2, 1, 2, 0, 1, 2, 1, 2, 1, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 3, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 2, 3, 3, 0, 0, 0, 0, 2, 0, 2, 1, 2, 3, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 3, 1, 1, 0, 0, 1, 2, 0, 1, 1, 0, 0, 1, 3, 2, 3, 1, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 3, 1, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0, 1, 2, 3, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 1, 2, 0, 1, 2, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 0, 0, 2, 2, 0, 1, 0, 2, 2, 0, 0, 2, 0, 1, 0, 1, 2, 2, 0, 2, 0, 2, 0, 0, 1, 0, 2, 2, 2, 0, 2, 1, 2, 1, 1, 1, 3, 0, 1, 0, 1, 1, 1, 1, 0, 2, 3, 0, 3, 3, 3, 2, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 1, 1, 3, 1, 0, 2, 0, 0, 0, 0, 2, 0, 3, 2, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 3, 1, 0, 0, 1, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 1, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 3, 3, 2, 2, 2, 2, 1, 0, 3, 1, 2, 1, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 2, 0, 2, 3, 0, 0, 0, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 2, 0, 1, 2, 1, 2, 2, 2, 0, 3, 0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 3, 2, 3, 0, 0, 0, 0, 2, 1, 0, 2, 2, 0, 2, 1, 1, 2, 2, 3, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 0, 2, 0, 0, 3, 3, 0, 3, 2, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 2, 3, 0, 0, 3, 2, 1, 2, 3, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 3, 0, 1, 3, 0, 1, 0, 2, 0, 2, 0, 1, 1, 0, 1, 2, 3, 1, 1, 1, 0, 2, 2, 1, 0, 2, 3, 1, 0, 2, 0, 1, 2, 0, 2, 0, 0, 0, 1, 2, 0, 2, 0, 2, 0, 2, 2, 3, 2, 3, 0, 2, 2, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 2, 1, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 2, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 2, 1, 0, 0, 2, 2, 0, 3, 0, 0, 2, 0, 2, 0, 1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 1, 3, 0, 0, 0, 0, 2, 1, 1, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 2, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 2, 2, 1, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 1, 1, 2, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 0, 0, 0, 1, 0, 3, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 1, 1, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 3, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 2, 0, 3, 0, 1, 1, 2, 2, 0, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0]\n",
            "Here is an example (from the train set):\n",
            "Input : acer wants $ 170 to just look at it then add the repair cost on top of that.\n",
            "tensor([   3,    9, 2110, 2746, 1514,  209, 2518,   12,  131,  320,   44,   34,\n",
            "         258,  617,    8, 2096,  583,   30,  420,   13,   24,    3,    5,    1,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0])\n",
            "Output: the support price | THE acer IS NULL | neutral\n",
            "tensor([    8,   380,   594,  1820,  1853,     3,     9,  2110,  6827, 13046,\n",
            "        10376,  1820,  7163,     1,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "\n",
            "****** Conducting Training ******\n",
            "Downloading: 100% 850M/850M [00:11<00:00, 74.6MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus='1')` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices='1')` instead.\n",
            "  rank_zero_deprecation(\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "\n",
            "  | Name       | Type                       | Params\n",
            "----------------------------------------------------------\n",
            "0 | model      | T5ForConditionalGeneration | 222 M \n",
            "1 | cont_model | LinearModel                | 21.5 K\n",
            "2 | op_model   | LinearModel                | 21.5 K\n",
            "3 | as_model   | LinearModel                | 21.5 K\n",
            "4 | cat_model  | LinearModel                | 21.5 K\n",
            "----------------------------------------------------------\n",
            "222 M     Trainable params\n",
            "0         Non-trainable params\n",
            "222 M     Total params\n",
            "891.876   Total estimated model params size (MB)\n",
            "Sanity Checking: 0it [00:00, ?it/s]Sentiment distribution\n",
            "Counter({2: 180, 0: 109, 3: 19, 1: 18})\n",
            "aspect : [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 0, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1]\n",
            "aspect_opinion : [0, 2, 3, 0, 0, 2, 0, 2, 0, 2, 3, 2, 2, 3, 0, 2, 0, 3, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 1, 0, 0, 1, 2, 1, 3, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 3, 0, 2, 2, 2, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 2, 0, 2, 1, 1, 3, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 1, 1, 0, 2, 0, 0, 1, 1, 0, 3, 1, 1, 2, 2, 2, 1, 3, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 3, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 3, 1, 1, 2, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 3, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 0, 3, 3, 0, 2, 0, 2, 2, 0, 0, 0, 2, 0, 1, 1, 0, 3, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Sanity Checking DataLoader 0: 100% 2/2 [00:01<00:00,  1.30it/s]val_loss:\t tensor(9.8461, device='cuda:0')\n",
            "Sentiment distribution\n",
            "Counter({2: 1584, 0: 1025, 1: 174, 3: 151})\n",
            "aspect : [1, 0, 0, 1, 2, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 2, 1, 1, 0, 2, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 1, 0, 1, 2, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 2, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 2, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 2, 0, 1, 0, 1, 2, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 2, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 2, 0, 1, 1, 1, 2, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 2, 0, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 1, 2, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 0, 0, 0, 1, 2, 1, 0, 1, 0, 1, 2, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 2, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 1, 1, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 2, 2, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 2, 1, 1, 1, 1, 0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 2, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 2, 2, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 2, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 2, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 2, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 0, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 0, 1, 2, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 1]\n",
            "aspect_opinion : [2, 3, 3, 2, 2, 0, 3, 1, 0, 2, 0, 1, 2, 2, 2, 3, 3, 0, 2, 2, 2, 2, 2, 0, 0, 1, 0, 0, 2, 2, 2, 0, 0, 3, 2, 2, 0, 3, 3, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 2, 1, 3, 0, 0, 1, 2, 2, 0, 2, 3, 0, 1, 3, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 3, 2, 1, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 3, 1, 1, 0, 1, 3, 0, 0, 0, 2, 2, 0, 2, 0, 0, 3, 3, 3, 3, 0, 3, 0, 0, 0, 3, 0, 3, 3, 0, 2, 2, 1, 0, 0, 2, 0, 1, 1, 0, 0, 2, 2, 2, 2, 2, 2, 1, 0, 2, 0, 2, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 2, 0, 1, 0, 2, 3, 2, 2, 0, 2, 2, 2, 3, 0, 1, 1, 2, 0, 2, 2, 2, 0, 1, 3, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 3, 3, 2, 2, 2, 2, 1, 0, 0, 2, 0, 0, 0, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 3, 1, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 1, 0, 0, 2, 0, 2, 3, 0, 0, 0, 2, 0, 0, 0, 2, 0, 1, 1, 0, 3, 0, 1, 0, 2, 2, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 3, 0, 0, 3, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 3, 2, 0, 2, 2, 2, 0, 0, 0, 1, 0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 1, 2, 3, 1, 1, 2, 1, 2, 1, 2, 2, 0, 0, 1, 3, 0, 1, 3, 3, 2, 1, 3, 3, 2, 1, 0, 0, 0, 0, 0, 0, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 3, 0, 3, 1, 0, 1, 1, 1, 0, 0, 0, 0, 2, 1, 3, 1, 1, 0, 0, 0, 2, 1, 2, 1, 1, 1, 1, 1, 2, 0, 3, 1, 0, 2, 1, 3, 0, 0, 3, 0, 0, 3, 3, 0, 1, 0, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 1, 2, 2, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 2, 0, 1, 1, 3, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 1, 3, 2, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 3, 3, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 3, 1, 2, 2, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 3, 1, 1, 0, 2, 1, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 3, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 3, 2, 0, 0, 2, 0, 1, 1, 1, 2, 2, 2, 1, 1, 0, 3, 1, 0, 0, 2, 0, 0, 2, 1, 0, 0, 0, 3, 2, 1, 0, 0, 1, 1, 1, 3, 0, 0, 0, 0, 0, 2, 2, 0, 1, 1, 1, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 1, 1, 2, 0, 0, 1, 0, 3, 3, 0, 0, 1, 2, 0, 1, 0, 2, 0, 2, 2, 1, 0, 0, 0, 0, 0, 1, 3, 3, 3, 1, 3, 3, 1, 0, 0, 1, 2, 2, 2, 2, 0, 1, 1, 1, 0, 0, 2, 2, 0, 0, 0, 2, 2, 1, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 1, 1, 1, 0, 0, 0, 3, 0, 1, 0, 0, 1, 2, 2, 2, 3, 3, 3, 3, 2, 0, 0, 1, 1, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 1, 3, 0, 3, 1, 0, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 2, 0, 1, 2, 1, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 3, 2, 0, 3, 0, 3, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 3, 3, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 3, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 3, 1, 1, 1, 1, 1, 2, 0, 0, 3, 0, 3, 1, 1, 1, 0, 1, 0, 0, 3, 3, 2, 2, 0, 0, 2, 2, 3, 1, 0, 2, 3, 0, 1, 1, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 3, 3, 0, 1, 1, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 3, 0, 3, 2, 1, 0, 2, 1, 0, 0, 3, 2, 1, 0, 1, 2, 0, 2, 3, 2, 2, 2, 1, 0, 2, 2, 0, 0, 1, 1, 0, 2, 0, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 1, 2, 2, 2, 0, 2, 0, 2, 1, 1, 2, 1, 0, 0, 0, 0, 2, 2, 2, 0, 2, 0, 3, 3, 2, 2, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 2, 1, 2, 0, 0, 3, 0, 1, 0, 2, 0, 1, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 3, 1, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 2, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 0, 2, 2, 2, 0, 3, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 3, 0, 0, 2, 2, 0, 1, 0, 3, 0, 0, 2, 0, 0, 0, 2, 0, 1, 1, 1, 1, 0, 1, 0, 2, 2, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 2, 0, 1, 0, 2, 3, 1, 1, 0, 2, 0, 2, 3, 0, 1, 3, 1, 1, 2, 2, 1, 3, 2, 0, 0, 2, 1, 2, 3, 2, 1, 3, 3, 2, 0, 1, 2, 2, 3, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 1, 2, 2, 3, 0, 1, 2, 2, 3, 0, 2, 3, 0, 0, 2, 2, 2, 2, 3, 0, 2, 2, 3, 2, 3, 0, 3, 3, 3, 2, 2, 0, 3, 3, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 1, 2, 1, 1, 3, 3, 2, 2, 2, 3, 3, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 2, 0, 3, 0, 1, 2, 2, 2, 2, 0, 3, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 0, 2, 0, 0, 0, 0, 1, 0, 1, 0, 2, 1, 0, 3, 2, 2, 0, 3, 2, 0, 2, 3, 3, 2, 2, 0, 3, 0, 2, 0, 2, 0, 0, 2, 3, 1, 0, 2, 2, 0, 0, 2, 3, 2, 0, 3, 0, 1, 0, 0, 0, 2, 0, 1, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 2, 2, 0, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 1, 2, 2, 3, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 3, 3, 3, 1, 0, 0, 0, 2, 2, 2, 1, 3, 3, 0, 2, 2, 1, 1, 1, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 3, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 1, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 0, 0, 2, 2, 1, 2, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 2, 3, 0, 1, 1, 0, 1, 0, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 3, 1, 1, 0, 0, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 2, 3, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 3, 0, 0, 0, 0, 0, 0, 3, 0, 2, 2, 2, 2, 3, 1, 0, 0, 2, 2, 0, 2, 2, 0, 0, 1, 0, 2, 0, 2, 2, 2, 1, 2, 2, 0, 0, 0, 2, 2, 0, 3, 3, 0, 1, 0, 0, 1, 2, 0, 0, 0, 0, 0, 3, 0, 3, 0, 1, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 2, 2, 0, 0, 0, 1, 0, 0, 3, 3, 1, 2, 0, 2, 1, 2, 0, 1, 2, 1, 2, 1, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 3, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 2, 3, 3, 0, 0, 0, 0, 2, 0, 2, 1, 2, 3, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 3, 1, 1, 0, 0, 1, 2, 0, 1, 1, 0, 0, 1, 3, 2, 3, 1, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 3, 1, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0, 1, 2, 3, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 1, 2, 0, 1, 2, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 0, 0, 2, 2, 0, 1, 0, 2, 2, 0, 0, 2, 0, 1, 0, 1, 2, 2, 0, 2, 0, 2, 0, 0, 1, 0, 2, 2, 2, 0, 2, 1, 2, 1, 1, 1, 3, 0, 1, 0, 1, 1, 1, 1, 0, 2, 3, 0, 3, 3, 3, 2, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 1, 1, 3, 1, 0, 2, 0, 0, 0, 0, 2, 0, 3, 2, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 3, 1, 0, 0, 1, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 1, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 3, 3, 2, 2, 2, 2, 1, 0, 3, 1, 2, 1, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 2, 0, 2, 3, 0, 0, 0, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 2, 0, 1, 2, 1, 2, 2, 2, 0, 3, 0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 3, 2, 3, 0, 0, 0, 0, 2, 1, 0, 2, 2, 0, 2, 1, 1, 2, 2, 3, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 0, 2, 0, 0, 3, 3, 0, 3, 2, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 2, 3, 0, 0, 3, 2, 1, 2, 3, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 3, 0, 1, 3, 0, 1, 0, 2, 0, 2, 0, 1, 1, 0, 1, 2, 3, 1, 1, 1, 0, 2, 2, 1, 0, 2, 3, 1, 0, 2, 0, 1, 2, 0, 2, 0, 0, 0, 1, 2, 0, 2, 0, 2, 0, 2, 2, 3, 2, 3, 0, 2, 2, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 2, 1, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 2, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 2, 1, 0, 0, 2, 2, 0, 3, 0, 0, 2, 0, 2, 0, 1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 1, 3, 0, 0, 0, 0, 2, 1, 1, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 2, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 2, 2, 1, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 1, 1, 2, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 0, 0, 0, 1, 0, 3, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 1, 1, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 3, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 2, 0, 3, 0, 1, 1, 2, 2, 0, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0]\n",
            "Epoch 0:  88% 180/204 [02:31<00:20,  1.19it/s, loss=2.4, v_num=1] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  98% 200/204 [02:39<00:03,  1.26it/s, loss=2.4, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.56it/s]\u001b[A\n",
            "Epoch 0: 100% 204/204 [02:40<00:00,  1.27it/s, loss=2.4, v_num=1]val_loss:\t tensor(2.1831, device='cuda:0')\n",
            "Epoch 0: 100% 204/204 [02:40<00:00,  1.27it/s, loss=2.41, v_num=1]\n",
            "Epoch 1:  88% 180/204 [02:34<00:20,  1.17it/s, loss=2.19, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  98% 200/204 [02:41<00:03,  1.24it/s, loss=2.19, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.53it/s]\u001b[A\n",
            "Epoch 1: 100% 204/204 [02:42<00:00,  1.25it/s, loss=2.19, v_num=1]val_loss:\t tensor(2.0661, device='cuda:0')\n",
            "Epoch 1: 100% 204/204 [02:42<00:00,  1.25it/s, loss=2.18, v_num=1]\n",
            "Epoch 2:  88% 180/204 [02:33<00:20,  1.17it/s, loss=2.05, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  98% 200/204 [02:41<00:03,  1.24it/s, loss=2.05, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.55it/s]\u001b[A\n",
            "Epoch 2: 100% 204/204 [02:42<00:00,  1.26it/s, loss=2.05, v_num=1]val_loss:\t tensor(2.0269, device='cuda:0')\n",
            "Epoch 2: 100% 204/204 [02:42<00:00,  1.26it/s, loss=2.05, v_num=1]\n",
            "Epoch 3:  88% 180/204 [02:33<00:20,  1.17it/s, loss=2.01, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  98% 200/204 [02:41<00:03,  1.24it/s, loss=2.01, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.54it/s]\u001b[A\n",
            "Epoch 3: 100% 204/204 [02:42<00:00,  1.26it/s, loss=2.01, v_num=1]val_loss:\t tensor(2.0112, device='cuda:0')\n",
            "Epoch 3: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.98, v_num=1]\n",
            "Epoch 4:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.9, v_num=1] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.9, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.54it/s]\u001b[A\n",
            "Epoch 4: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.9, v_num=1]val_loss:\t tensor(1.9620, device='cuda:0')\n",
            "Epoch 4: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.89, v_num=1]\n",
            "Epoch 5:  88% 180/204 [02:34<00:20,  1.17it/s, loss=1.82, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:  98% 200/204 [02:41<00:03,  1.23it/s, loss=1.82, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.53it/s]\u001b[A\n",
            "Epoch 5: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.82, v_num=1]val_loss:\t tensor(1.9500, device='cuda:0')\n",
            "Epoch 5: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.81, v_num=1]\n",
            "Epoch 6:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.7, v_num=1] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.7, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.55it/s]\u001b[A\n",
            "Epoch 6: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.7, v_num=1]val_loss:\t tensor(2.0049, device='cuda:0')\n",
            "Epoch 6: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.69, v_num=1]\n",
            "Epoch 7:  88% 180/204 [02:34<00:20,  1.17it/s, loss=1.69, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.69, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.55it/s]\u001b[A\n",
            "Epoch 7: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.69, v_num=1]val_loss:\t tensor(2.0222, device='cuda:0')\n",
            "Epoch 7: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.7, v_num=1] \n",
            "Epoch 8:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.65, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.65, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.54it/s]\u001b[A\n",
            "Epoch 8: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.65, v_num=1]val_loss:\t tensor(2.0383, device='cuda:0')\n",
            "Epoch 8: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.65, v_num=1]\n",
            "Epoch 9:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.64, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.64, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.56it/s]\u001b[A\n",
            "Epoch 9: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.64, v_num=1]val_loss:\t tensor(2.0733, device='cuda:0')\n",
            "Epoch 9: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.62, v_num=1]\n",
            "Epoch 10:  88% 180/204 [02:34<00:20,  1.17it/s, loss=1.6, v_num=1] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 10:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.6, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.55it/s]\u001b[A\n",
            "Epoch 10: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.6, v_num=1]val_loss:\t tensor(2.0482, device='cuda:0')\n",
            "Epoch 10: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.6, v_num=1]\n",
            "Epoch 11:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.58, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 11:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.58, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.56it/s]\u001b[A\n",
            "Epoch 11: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.58, v_num=1]val_loss:\t tensor(2.1001, device='cuda:0')\n",
            "Epoch 11: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.58, v_num=1]\n",
            "Epoch 12:  88% 180/204 [02:34<00:20,  1.17it/s, loss=1.56, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 12:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.56, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.55it/s]\u001b[A\n",
            "Epoch 12: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.56, v_num=1]val_loss:\t tensor(2.1354, device='cuda:0')\n",
            "Epoch 12: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.58, v_num=1]\n",
            "Epoch 13:  88% 180/204 [02:34<00:20,  1.17it/s, loss=1.55, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 13:  98% 200/204 [02:41<00:03,  1.23it/s, loss=1.55, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.55it/s]\u001b[A\n",
            "Epoch 13: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.55, v_num=1]val_loss:\t tensor(2.1459, device='cuda:0')\n",
            "Epoch 13: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.55, v_num=1]\n",
            "Epoch 14:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.54, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 14:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.54, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.53it/s]\u001b[A\n",
            "Epoch 14: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.54, v_num=1]val_loss:\t tensor(2.1674, device='cuda:0')\n",
            "Epoch 14: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.53, v_num=1]\n",
            "Epoch 15:  88% 180/204 [02:34<00:20,  1.17it/s, loss=1.52, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 15:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.52, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.56it/s]\u001b[A\n",
            "Epoch 15: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.52, v_num=1]val_loss:\t tensor(2.1890, device='cuda:0')\n",
            "Epoch 15: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.51, v_num=1]\n",
            "Epoch 16:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.51, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 16:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.51, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.56it/s]\u001b[A\n",
            "Epoch 16: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.51, v_num=1]val_loss:\t tensor(2.2339, device='cuda:0')\n",
            "Epoch 16: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.51, v_num=1]\n",
            "Epoch 17:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.5, v_num=1] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 17:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.5, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.54it/s]\u001b[A\n",
            "Epoch 17: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.5, v_num=1]val_loss:\t tensor(2.2036, device='cuda:0')\n",
            "Epoch 17: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.51, v_num=1]\n",
            "Epoch 18:  88% 180/204 [02:34<00:20,  1.17it/s, loss=1.47, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 18:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.47, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.57it/s]\u001b[A\n",
            "Epoch 18: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.47, v_num=1]val_loss:\t tensor(2.2434, device='cuda:0')\n",
            "Epoch 18: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.47, v_num=1]\n",
            "Epoch 19:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.47, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 19:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.47, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.54it/s]\u001b[A\n",
            "Epoch 19: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.47, v_num=1]val_loss:\t tensor(2.2336, device='cuda:0')\n",
            "Epoch 19: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.48, v_num=1]\n",
            "Epoch 20:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.47, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 20:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.47, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.55it/s]\u001b[A\n",
            "Epoch 20: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.47, v_num=1]val_loss:\t tensor(2.2454, device='cuda:0')\n",
            "Epoch 20: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.47, v_num=1]\n",
            "Epoch 21:  88% 180/204 [02:34<00:20,  1.17it/s, loss=1.48, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 21:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.48, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.58it/s]\u001b[A\n",
            "Epoch 21: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.48, v_num=1]val_loss:\t tensor(2.2497, device='cuda:0')\n",
            "Epoch 21: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.47, v_num=1]\n",
            "Epoch 22:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.46, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 22:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.46, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.55it/s]\u001b[A\n",
            "Epoch 22: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.46, v_num=1]val_loss:\t tensor(2.2332, device='cuda:0')\n",
            "Epoch 22: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.46, v_num=1]\n",
            "Epoch 23:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.43, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 23:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.43, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.56it/s]\u001b[A\n",
            "Epoch 23: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.43, v_num=1]val_loss:\t tensor(2.2784, device='cuda:0')\n",
            "Epoch 23: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.43, v_num=1]\n",
            "Epoch 24:  88% 180/204 [02:34<00:20,  1.16it/s, loss=1.45, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 24:  98% 200/204 [02:42<00:03,  1.23it/s, loss=1.45, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.58it/s]\u001b[A\n",
            "Epoch 24: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.45, v_num=1]val_loss:\t tensor(2.3058, device='cuda:0')\n",
            "Epoch 24: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.44, v_num=1]\n",
            "Epoch 25:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.45, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 25:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.45, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.54it/s]\u001b[A\n",
            "Epoch 25: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.45, v_num=1]val_loss:\t tensor(2.2951, device='cuda:0')\n",
            "Epoch 25: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.42, v_num=1]\n",
            "Epoch 26:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.43, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 26:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.43, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.55it/s]\u001b[A\n",
            "Epoch 26: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.43, v_num=1]val_loss:\t tensor(2.2923, device='cuda:0')\n",
            "Epoch 26: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.42, v_num=1]\n",
            "Epoch 27:  88% 180/204 [02:34<00:20,  1.17it/s, loss=1.43, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 27:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.43, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.56it/s]\u001b[A\n",
            "Epoch 27: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.43, v_num=1]val_loss:\t tensor(2.3076, device='cuda:0')\n",
            "Epoch 27: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.44, v_num=1]\n",
            "Epoch 28:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.44, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 28:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.44, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.54it/s]\u001b[A\n",
            "Epoch 28: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.44, v_num=1]val_loss:\t tensor(2.3297, device='cuda:0')\n",
            "Epoch 28: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.44, v_num=1]\n",
            "Epoch 29:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.43, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 29:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.43, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.57it/s]\u001b[A\n",
            "Epoch 29: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.43, v_num=1]val_loss:\t tensor(2.3250, device='cuda:0')\n",
            "Epoch 29: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.44, v_num=1]\n",
            "Epoch 30:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.43, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 30:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.43, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.56it/s]\u001b[A\n",
            "Epoch 30: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.43, v_num=1]val_loss:\t tensor(2.3235, device='cuda:0')\n",
            "Epoch 30: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.43, v_num=1]\n",
            "Epoch 31:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.42, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 31:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.42, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.55it/s]\u001b[A\n",
            "Epoch 31: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.42, v_num=1]val_loss:\t tensor(2.3360, device='cuda:0')\n",
            "Epoch 31: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.41, v_num=1]\n",
            "Epoch 32:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.43, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 32:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.43, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.56it/s]\u001b[A\n",
            "Epoch 32: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.43, v_num=1]val_loss:\t tensor(2.3521, device='cuda:0')\n",
            "Epoch 32: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.43, v_num=1]\n",
            "Epoch 33:  88% 180/204 [02:34<00:20,  1.17it/s, loss=1.43, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 33:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.43, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.57it/s]\u001b[A\n",
            "Epoch 33: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.43, v_num=1]val_loss:\t tensor(2.3596, device='cuda:0')\n",
            "Epoch 33: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.43, v_num=1]\n",
            "Epoch 34:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.42, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 34:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.42, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.54it/s]\u001b[A\n",
            "Epoch 34: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.42, v_num=1]val_loss:\t tensor(2.3564, device='cuda:0')\n",
            "Epoch 34: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.41, v_num=1]\n",
            "Epoch 35:  88% 180/204 [02:34<00:20,  1.17it/s, loss=1.42, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 35:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.42, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.55it/s]\u001b[A\n",
            "Epoch 35: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.42, v_num=1]val_loss:\t tensor(2.3472, device='cuda:0')\n",
            "Epoch 35: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.42, v_num=1]\n",
            "Epoch 36:  88% 180/204 [02:34<00:20,  1.17it/s, loss=1.41, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 36:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.41, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.56it/s]\u001b[A\n",
            "Epoch 36: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.41, v_num=1]val_loss:\t tensor(2.3275, device='cuda:0')\n",
            "Epoch 36: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.41, v_num=1]\n",
            "Epoch 37:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.41, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 37:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.41, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.54it/s]\u001b[A\n",
            "Epoch 37: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.41, v_num=1]val_loss:\t tensor(2.3421, device='cuda:0')\n",
            "Epoch 37: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.42, v_num=1]\n",
            "Epoch 38:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.4, v_num=1] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 38:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.4, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.55it/s]\u001b[A\n",
            "Epoch 38: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.4, v_num=1]val_loss:\t tensor(2.3611, device='cuda:0')\n",
            "Epoch 38: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.41, v_num=1]\n",
            "Epoch 39:  88% 180/204 [02:34<00:20,  1.17it/s, loss=1.41, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 39:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.41, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.55it/s]\u001b[A\n",
            "Epoch 39: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.41, v_num=1]val_loss:\t tensor(2.3623, device='cuda:0')\n",
            "Epoch 39: 100% 204/204 [02:42<00:00,  1.25it/s, loss=1.4, v_num=1] \n",
            "Epoch 40:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.43, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 40:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.43, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.52it/s]\u001b[A\n",
            "Epoch 40: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.43, v_num=1]val_loss:\t tensor(2.3952, device='cuda:0')\n",
            "Epoch 40: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.42, v_num=1]\n",
            "Epoch 41:  88% 180/204 [02:33<00:20,  1.17it/s, loss=1.42, v_num=1]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 41:  98% 200/204 [02:41<00:03,  1.24it/s, loss=1.42, v_num=1]\n",
            "Validation DataLoader 0:  95% 20/21 [00:05<00:00,  3.56it/s]\u001b[A\n",
            "Epoch 41: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.42, v_num=1]val_loss:\t tensor(2.3670, device='cuda:0')\n",
            "Epoch 41: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.43, v_num=1]\n",
            "Epoch 41: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.43, v_num=1]`Trainer.fit` stopped: `max_epochs=42` reached.\n",
            "Epoch 41: 100% 204/204 [02:42<00:00,  1.26it/s, loss=1.43, v_num=1]\n",
            "Finish training and saving the model!\n",
            "\n",
            "****** Conduct Evaluating with the last state ******\n",
            "\n",
            "Sentiment distribution\n",
            "Counter({2: 449, 0: 279, 1: 52, 3: 36})\n",
            "aspect : [1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 0, 1, 0, 1, 1, 1, 2, 0, 1, 1, 1, 0, 2, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 0, 1, 1, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 2, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1]\n",
            "aspect_opinion : [0, 0, 2, 0, 2, 2, 1, 3, 0, 0, 1, 0, 0, 0, 2, 2, 2, 3, 2, 0, 3, 0, 0, 2, 1, 3, 0, 2, 1, 3, 0, 2, 2, 1, 2, 2, 0, 0, 1, 2, 1, 1, 0, 1, 1, 3, 0, 0, 2, 2, 2, 1, 2, 3, 2, 0, 0, 2, 0, 0, 2, 2, 2, 1, 1, 2, 0, 2, 2, 0, 2, 2, 0, 1, 3, 0, 2, 3, 3, 2, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 1, 0, 2, 2, 1, 1, 1, 2, 2, 3, 0, 3, 2, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 2, 2, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 2, 2, 0, 0, 3, 3, 3, 0, 2, 2, 1, 0, 0, 0, 0, 3, 3, 2, 0, 1, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 1, 0, 3, 1, 2, 1, 2, 1, 0, 1, 0, 0, 0, 2, 2, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 2, 2, 2, 2, 0, 3, 3, 0, 3, 0, 0, 0, 1, 0, 0, 2, 1, 3, 0, 0, 0, 3, 2, 0, 0, 2, 0, 2, 2, 2, 0, 0, 1, 3, 2, 0, 2, 0, 2, 1, 0, 0, 1, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 1, 3, 2, 3, 2, 0, 2, 1, 1, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 2, 3, 1, 1, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 3, 3, 3, 2, 2, 0, 2, 0, 1, 2, 3, 0, 0, 0, 0, 1, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 3, 2, 3, 1, 2, 0, 1, 0, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 2, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 1, 1, 1, 0, 0, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 3, 0, 2, 0, 0, 0, 2, 0, 0, 0, 3, 2, 0, 3, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 1, 2, 2, 2, 0, 0, 0, 1, 0, 0, 2, 2, 1, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 2, 0, 2, 0, 0, 0, 1, 1, 1, 2, 0, 0, 0, 2, 3, 0, 0, 0, 2, 2, 2, 1, 1, 0, 1, 1, 1, 0, 0, 3, 0, 0, 0, 0, 3, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 0, 1, 2, 0, 0, 3, 0, 2, 2, 1, 0, 0, 1, 2, 2, 2, 0, 1, 0, 0, 2, 2, 2, 2, 3, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 1, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 0, 2, 2, 0, 3, 3, 3, 3, 0, 3, 0, 2, 0, 3, 2, 1, 0, 0, 2, 3, 0, 3, 1, 2, 3, 0, 2, 2, 2, 2, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 2, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 2, 0, 2, 3, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 3, 1, 0, 2, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 2, 0, 3, 1, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "100% 51/51 [03:26<00:00,  4.06s/it]\n",
            "\n",
            "Results:\n",
            "number of gold spans: 1156, predicted spans: 1150, hit: 506\n",
            "{'precision': 0.44, 'recall': 0.43771626297577854, 'f1': 0.4388551604509974}\n"
          ]
        }
      ],
      "source": [
        "!python gen_scl_nat_main1.py \\\n",
        "   --task gen_scl_nat \\\n",
        "   --do_train\\\n",
        "   --do_direct_eval\\\n",
        "   --dataset \\acos_laptop_data \\\n",
        "   --model_name_or_path t5-base \\\n",
        "   --output_folder inference_outputs \\\n",
        "   --n_gpu 1 \\\n",
        "   --train_batch_size 16 \\\n",
        "   --eval_batch_size 16 \\\n",
        "   --learning_rate 9e-5 \\\n",
        "   --gradient_accumulation_steps 1 \\\n",
        "   --num_train_epochs 42 \\\n",
        "   --num_beams 5 \\\n",
        "   --weight_decay 0.0 \\\n",
        "   --seed 123 \\\n",
        "   --cont_loss 0.05 \\\n",
        "   --cont_temp 0.25 \\\n",
        "   --model_prefix restaurant_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python gen_scl_nat_main.py \\\n",
        "   --task gen_scl_nat \\\n",
        "   --do_inference \\\n",
        "   --dataset acos_laptop_data \\\n",
        "   --model_name_or_path models/GEN_SCL_NAT-RESTAURANT \\\n",
        "   --output_folder inference_outputs \\\n",
        "   --n_gpu 1 \\\n",
        "   --train_batch_size 32 \\\n",
        "   --eval_batch_size 32 \\\n",
        "   --learning_rate 9e-5 \\\n",
        "   --gradient_accumulation_steps 1 \\\n",
        "   --num_train_epochs 45 \\\n",
        "   --num_beams 5 \\\n",
        "   --weight_decay 0.0 \\\n",
        "   --seed 123 \\\n",
        "   --cont_loss 0.05 \\\n",
        "   --cont_temp 0.25 \\\n",
        "   --model_prefix restaurant_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z69lMmcJNOGQ",
        "outputId": "1ddda916-00e6-497b-de2c-64a6a6c9e920"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-24 05:37:33.072104: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-24 05:37:33.072160: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-24 05:37:33.072196: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-24 05:37:33.079924: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-24 05:37:34.227251: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "restaurant_output\n",
            "Global seed set to 123\n",
            "Sentiment distribution\n",
            "Counter({2: 1584, 0: 1025, 1: 174, 3: 151})\n",
            "aspect : [1, 0, 0, 1, 2, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 2, 1, 1, 0, 2, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 1, 0, 1, 2, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 2, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 2, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 2, 0, 1, 0, 1, 2, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 2, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 2, 0, 1, 1, 1, 2, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 2, 0, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 1, 2, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 0, 0, 0, 1, 2, 1, 0, 1, 0, 1, 2, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 2, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 1, 1, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 2, 2, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 2, 1, 1, 1, 1, 0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 2, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 2, 2, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 2, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 2, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 2, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 0, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 0, 1, 2, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 1]\n",
            "aspect_opinion : [2, 3, 3, 2, 2, 0, 3, 1, 0, 2, 0, 1, 2, 2, 2, 3, 3, 0, 2, 2, 2, 2, 2, 0, 0, 1, 0, 0, 2, 2, 2, 0, 0, 3, 2, 2, 0, 3, 3, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 2, 1, 3, 0, 0, 1, 2, 2, 0, 2, 3, 0, 1, 3, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 3, 2, 1, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 3, 1, 1, 0, 1, 3, 0, 0, 0, 2, 2, 0, 2, 0, 0, 3, 3, 3, 3, 0, 3, 0, 0, 0, 3, 0, 3, 3, 0, 2, 2, 1, 0, 0, 2, 0, 1, 1, 0, 0, 2, 2, 2, 2, 2, 2, 1, 0, 2, 0, 2, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 2, 0, 1, 0, 2, 3, 2, 2, 0, 2, 2, 2, 3, 0, 1, 1, 2, 0, 2, 2, 2, 0, 1, 3, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 3, 3, 2, 2, 2, 2, 1, 0, 0, 2, 0, 0, 0, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 3, 1, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 1, 0, 0, 2, 0, 2, 3, 0, 0, 0, 2, 0, 0, 0, 2, 0, 1, 1, 0, 3, 0, 1, 0, 2, 2, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 3, 0, 0, 3, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 3, 2, 0, 2, 2, 2, 0, 0, 0, 1, 0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 1, 2, 3, 1, 1, 2, 1, 2, 1, 2, 2, 0, 0, 1, 3, 0, 1, 3, 3, 2, 1, 3, 3, 2, 1, 0, 0, 0, 0, 0, 0, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 3, 0, 3, 1, 0, 1, 1, 1, 0, 0, 0, 0, 2, 1, 3, 1, 1, 0, 0, 0, 2, 1, 2, 1, 1, 1, 1, 1, 2, 0, 3, 1, 0, 2, 1, 3, 0, 0, 3, 0, 0, 3, 3, 0, 1, 0, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 1, 2, 2, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 2, 0, 1, 1, 3, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 1, 3, 2, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 3, 3, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 3, 1, 2, 2, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 3, 1, 1, 0, 2, 1, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 3, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 3, 2, 0, 0, 2, 0, 1, 1, 1, 2, 2, 2, 1, 1, 0, 3, 1, 0, 0, 2, 0, 0, 2, 1, 0, 0, 0, 3, 2, 1, 0, 0, 1, 1, 1, 3, 0, 0, 0, 0, 0, 2, 2, 0, 1, 1, 1, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 1, 1, 2, 0, 0, 1, 0, 3, 3, 0, 0, 1, 2, 0, 1, 0, 2, 0, 2, 2, 1, 0, 0, 0, 0, 0, 1, 3, 3, 3, 1, 3, 3, 1, 0, 0, 1, 2, 2, 2, 2, 0, 1, 1, 1, 0, 0, 2, 2, 0, 0, 0, 2, 2, 1, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 2, 0, 1, 1, 1, 1, 1, 0, 0, 0, 3, 0, 1, 0, 0, 1, 2, 2, 2, 3, 3, 3, 3, 2, 0, 0, 1, 1, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 1, 3, 0, 3, 1, 0, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 2, 0, 1, 2, 1, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 3, 2, 0, 3, 0, 3, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 3, 3, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 3, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 3, 1, 1, 1, 1, 1, 2, 0, 0, 3, 0, 3, 1, 1, 1, 0, 1, 0, 0, 3, 3, 2, 2, 0, 0, 2, 2, 3, 1, 0, 2, 3, 0, 1, 1, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 3, 3, 0, 1, 1, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 3, 0, 3, 2, 1, 0, 2, 1, 0, 0, 3, 2, 1, 0, 1, 2, 0, 2, 3, 2, 2, 2, 1, 0, 2, 2, 0, 0, 1, 1, 0, 2, 0, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 1, 2, 2, 2, 0, 2, 0, 2, 1, 1, 2, 1, 0, 0, 0, 0, 2, 2, 2, 0, 2, 0, 3, 3, 2, 2, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 2, 1, 2, 0, 0, 3, 0, 1, 0, 2, 0, 1, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 3, 1, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 2, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 0, 2, 2, 2, 0, 3, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 3, 0, 0, 2, 2, 0, 1, 0, 3, 0, 0, 2, 0, 0, 0, 2, 0, 1, 1, 1, 1, 0, 1, 0, 2, 2, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 2, 0, 1, 0, 2, 3, 1, 1, 0, 2, 0, 2, 3, 0, 1, 3, 1, 1, 2, 2, 1, 3, 2, 0, 0, 2, 1, 2, 3, 2, 1, 3, 3, 2, 0, 1, 2, 2, 3, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 1, 2, 2, 3, 0, 1, 2, 2, 3, 0, 2, 3, 0, 0, 2, 2, 2, 2, 3, 0, 2, 2, 3, 2, 3, 0, 3, 3, 3, 2, 2, 0, 3, 3, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 1, 2, 1, 1, 3, 3, 2, 2, 2, 3, 3, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 2, 0, 3, 0, 1, 2, 2, 2, 2, 0, 3, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 0, 2, 0, 0, 0, 0, 1, 0, 1, 0, 2, 1, 0, 3, 2, 2, 0, 3, 2, 0, 2, 3, 3, 2, 2, 0, 3, 0, 2, 0, 2, 0, 0, 2, 3, 1, 0, 2, 2, 0, 0, 2, 3, 2, 0, 3, 0, 1, 0, 0, 0, 2, 0, 1, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 2, 2, 0, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 1, 2, 2, 3, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 3, 3, 3, 1, 0, 0, 0, 2, 2, 2, 1, 3, 3, 0, 2, 2, 1, 1, 1, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 3, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 1, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 0, 0, 2, 2, 1, 2, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 2, 3, 0, 1, 1, 0, 1, 0, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 3, 1, 1, 0, 0, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 2, 3, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 3, 0, 0, 0, 0, 0, 0, 3, 0, 2, 2, 2, 2, 3, 1, 0, 0, 2, 2, 0, 2, 2, 0, 0, 1, 0, 2, 0, 2, 2, 2, 1, 2, 2, 0, 0, 0, 2, 2, 0, 3, 3, 0, 1, 0, 0, 1, 2, 0, 0, 0, 0, 0, 3, 0, 3, 0, 1, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 2, 2, 0, 0, 0, 1, 0, 0, 3, 3, 1, 2, 0, 2, 1, 2, 0, 1, 2, 1, 2, 1, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 3, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 2, 3, 3, 0, 0, 0, 0, 2, 0, 2, 1, 2, 3, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 3, 1, 1, 0, 0, 1, 2, 0, 1, 1, 0, 0, 1, 3, 2, 3, 1, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 3, 1, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0, 1, 2, 3, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 1, 2, 0, 1, 2, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 0, 0, 2, 2, 0, 1, 0, 2, 2, 0, 0, 2, 0, 1, 0, 1, 2, 2, 0, 2, 0, 2, 0, 0, 1, 0, 2, 2, 2, 0, 2, 1, 2, 1, 1, 1, 3, 0, 1, 0, 1, 1, 1, 1, 0, 2, 3, 0, 3, 3, 3, 2, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 1, 1, 3, 1, 0, 2, 0, 0, 0, 0, 2, 0, 3, 2, 0, 2, 0, 0, 2, 0, 0, 2, 2, 0, 3, 1, 0, 0, 1, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 1, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 3, 3, 2, 2, 2, 2, 1, 0, 3, 1, 2, 1, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 2, 0, 2, 3, 0, 0, 0, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 2, 0, 1, 2, 1, 2, 2, 2, 0, 3, 0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 3, 2, 3, 0, 0, 0, 0, 2, 1, 0, 2, 2, 0, 2, 1, 1, 2, 2, 3, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 0, 2, 0, 0, 3, 3, 0, 3, 2, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 2, 3, 0, 0, 3, 2, 1, 2, 3, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 3, 0, 1, 3, 0, 1, 0, 2, 0, 2, 0, 1, 1, 0, 1, 2, 3, 1, 1, 1, 0, 2, 2, 1, 0, 2, 3, 1, 0, 2, 0, 1, 2, 0, 2, 0, 0, 0, 1, 2, 0, 2, 0, 2, 0, 2, 2, 3, 2, 3, 0, 2, 2, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 2, 1, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 2, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 2, 1, 0, 0, 2, 2, 0, 3, 0, 0, 2, 0, 2, 0, 1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 1, 3, 0, 0, 0, 0, 2, 1, 1, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 2, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 2, 2, 1, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 1, 1, 2, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 0, 0, 0, 1, 0, 3, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 1, 1, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 3, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 2, 0, 3, 0, 1, 1, 2, 2, 0, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0]\n",
            "Here is an example (from the train set):\n",
            "Input : acer wants $ 170 to just look at it then add the repair cost on top of that.\n",
            "tensor([   3,    9, 2110, 2746, 1514,  209, 2518,   12,  131,  320,   44,   34,\n",
            "         258,  617,    8, 2096,  583,   30,  420,   13,   24,    3,    5,    1,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0])\n",
            "Output: the support price | THE acer IS NULL | neutral\n",
            "tensor([    8,   380,   594,  1820,  1853,     3,     9,  2110,  6827, 13046,\n",
            "        10376,  1820,  7163,     1,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "\n",
            "****** Conduct inference on trained checkpoint ******\n",
            "Loading trained model from models/GEN_SCL_NAT-RESTAURANT\n",
            "\n",
            "Sentiment distribution\n",
            "Counter({2: 449, 0: 279, 1: 52, 3: 36})\n",
            "aspect : [1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 0, 1, 0, 1, 1, 1, 2, 0, 1, 1, 1, 0, 2, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 0, 1, 1, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 2, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1]\n",
            "aspect_opinion : [0, 0, 2, 0, 2, 2, 1, 3, 0, 0, 1, 0, 0, 0, 2, 2, 2, 3, 2, 0, 3, 0, 0, 2, 1, 3, 0, 2, 1, 3, 0, 2, 2, 1, 2, 2, 0, 0, 1, 2, 1, 1, 0, 1, 1, 3, 0, 0, 2, 2, 2, 1, 2, 3, 2, 0, 0, 2, 0, 0, 2, 2, 2, 1, 1, 2, 0, 2, 2, 0, 2, 2, 0, 1, 3, 0, 2, 3, 3, 2, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 1, 0, 2, 2, 1, 1, 1, 2, 2, 3, 0, 3, 2, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 2, 2, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 2, 2, 0, 0, 3, 3, 3, 0, 2, 2, 1, 0, 0, 0, 0, 3, 3, 2, 0, 1, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 1, 0, 3, 1, 2, 1, 2, 1, 0, 1, 0, 0, 0, 2, 2, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 2, 2, 2, 2, 0, 3, 3, 0, 3, 0, 0, 0, 1, 0, 0, 2, 1, 3, 0, 0, 0, 3, 2, 0, 0, 2, 0, 2, 2, 2, 0, 0, 1, 3, 2, 0, 2, 0, 2, 1, 0, 0, 1, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 1, 3, 2, 3, 2, 0, 2, 1, 1, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 2, 3, 1, 1, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 3, 3, 3, 2, 2, 0, 2, 0, 1, 2, 3, 0, 0, 0, 0, 1, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 3, 2, 3, 1, 2, 0, 1, 0, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 2, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 1, 1, 1, 0, 0, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 3, 0, 2, 0, 0, 0, 2, 0, 0, 0, 3, 2, 0, 3, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 1, 2, 2, 2, 0, 0, 0, 1, 0, 0, 2, 2, 1, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 2, 0, 2, 0, 0, 0, 1, 1, 1, 2, 0, 0, 0, 2, 3, 0, 0, 0, 2, 2, 2, 1, 1, 0, 1, 1, 1, 0, 0, 3, 0, 0, 0, 0, 3, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 0, 1, 2, 0, 0, 3, 0, 2, 2, 1, 0, 0, 1, 2, 2, 2, 0, 1, 0, 0, 2, 2, 2, 2, 3, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 1, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 0, 2, 2, 0, 3, 3, 3, 3, 0, 3, 0, 2, 0, 3, 2, 1, 0, 0, 2, 3, 0, 3, 1, 2, 3, 0, 2, 2, 2, 2, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 2, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 2, 0, 2, 3, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 3, 1, 0, 2, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 2, 0, 3, 1, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 26/26 [02:10<00:00,  5.03s/it]\n",
            "\n",
            "Results:\n",
            "number of gold spans: 1156, predicted spans: 1150, hit: 506\n",
            "{'precision': 0.44, 'recall': 0.43771626297577854, 'f1': 0.4388551604509974}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ais2fvXyxd3l"
      },
      "source": [
        "# 新段落"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}